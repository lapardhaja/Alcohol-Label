\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{tabularx}

\geometry{margin=1in}
\lstset{basicstyle=\ttfamily\small, breaklines=true, frame=single, backgroundcolor=\color{gray!10}}

\title{BottleProof\\Approach, Tools, Assumptions \& Limitations}
\author{}
\date{}

\begin{document}
\maketitle

\section{What We Are Doing}

BottleProof is a TTB label compliance verification prototype. It checks whether a label image matches the application data the producer submitted. TTB agents handle around 150k label applications per year; this automates the routine comparison work.

Given a label image and application data, the system runs OCR, extracts key fields (brand, class/type, ABV, proof, net contents, government warning, bottler, country of origin), compares them against the application using configurable rules, and outputs a checklist with Pass / Needs review / Fail per field. Overall status is Ready to approve, Needs review, or Critical issues.

\section{How It Works}

\subsection{Process}

You upload a label image and the application data. The system:

\begin{enumerate}
    \item Preprocesses the image --- deskew, CLAHE contrast, sharpen, binarize --- so OCR has a cleaner input.
    \item Runs Tesseract OCR in multiple passes (PSM 3 and 6 on original, sharpened, and binary versions) to read text from the label.
    \item Deduplicates overlapping or repeated text blocks.
    \item Extracts fields from the OCR output using layout heuristics, regex, and common patterns (e.g.\ ``Distilled by'' before bottler name).
    \item Compares extracted values to the application. Exact match = Pass, close match = Needs review, mismatch or missing = Fail.
    \item Assigns overall status: any Fail $\rightarrow$ Critical issues; any Needs review $\rightarrow$ Needs review; otherwise Ready to approve.
\end{enumerate}

You get a checklist per field plus the overall status.

\subsection{Single vs batch mode}

Single label: upload one image, fill the form, click ``Check label''. Batch: upload a ZIP of images and a CSV with one row per label. The CSV must have a \texttt{label\_id} column matching the filename (e.g.\ \texttt{test\_1.png} $\rightarrow$ \texttt{test\_1}). You can filter by status and drill into any label.

\subsection{Approve flow}

Applications can be moved between ``Under review'', ``Approved'', and ``Rejected''. State is stored in \texttt{data/applications.json} (local, offline).

\subsection{Technical flow}

\begin{lstlisting}
Label image + Application data
    -> Preprocess (resize, deskew, CLAHE, sharpen, binarize)
    -> Tesseract OCR (multi-pass: PSM 3, 6 on original/sharpened/binary)
    -> Deduplicate blocks (IoU + fuzzy similarity)
    -> Field extraction (heuristics, regex, spatial layout)
    -> Rule engine (compare extracted vs application; config-driven thresholds)
    -> Scoring (any Fail -> Critical; any Needs review -> Needs review; else Ready to approve)
    -> UI: checklist
\end{lstlisting}

\section{Innovations}

\textbf{Speed and agent efficiency.} The system runs entirely locally --- no cloud API calls, no network latency. A single label check completes in seconds. For TTB agents handling $\sim$150k applications per year, that means a fast first scan on the essential fields (brand, class/type, ABV, proof, net contents, government warning, bottler, origin) before they dig into details. The agent gets an immediate Pass / Needs review / Fail per field and an overall status. Clear triage: obvious passes can move quickly; issues surface without manual line-by-line comparison. That first-pass automation saves time at scale.

\textbf{Better OCR from multiple passes.} Instead of a single OCR run, the system runs Tesseract three times on different preprocessed versions of the image (original, contrast-enhanced+sharpened, binarized). Each pass catches text the others miss. Results are merged and deduplicated: when two blocks overlap (same region on the label), we keep the one with higher confidence. Overlap is measured with IoU (Intersection over Union) --- the overlap area of two rectangles divided by their combined area; high IoU means ``same spot.'' Fuzzy similarity on the text helps decide when two blocks are duplicates even if OCR read them slightly differently. The result is more complete and cleaner extraction than a single pass.

\textbf{OCR-tolerant matching.} Label scans produce typos and confusables (1/l, 0/O, Mat vs Malt). The rule engine uses fuzzy matching (rapidfuzz) for brand, class/type, and government warning, with configurable pass/review thresholds. Minor OCR errors do not cause false fails. The government warning also gets spell correction before comparison, so common scan mistakes do not trigger unnecessary needs-review.

\textbf{Config-driven, no-code tuning.} Thresholds, patterns, beverage-type rules, and standard-of-fill lists live in \texttt{config/rules.yaml}. Adjusting pass vs needs-review sensitivity or adding new class/type keywords does not require code changes.

\section{Tools Used}

\begin{table}[h]
\centering
\small
\begin{tabularx}{\textwidth}{@{}l l X@{}}
\toprule
\textbf{Tool} & \textbf{Version / Notes} & \textbf{Purpose} \\
\midrule
Python & 3.10+ & Runtime \\
Streamlit & $\geq$1.28 & Web UI \\
Tesseract OCR & 5.x (system-installed) & Text recognition from label images \\
pytesseract & $\geq$0.3.10 & Python bindings for Tesseract \\
OpenCV (opencv-python-headless) & $\geq$4.8 & Image preprocessing: deskew, CLAHE, sharpen, binarization (Otsu) \\
Pillow & $\geq$10.0 & Image I/O, resize \\
PyYAML & $\geq$6.0 & Load \texttt{config/rules.yaml} \\
rapidfuzz & $\geq$3.0 & Fuzzy string matching (brand, class/type, warning) \\
pyspellchecker & $\geq$0.8.0 & OCR error correction in government warning text \\
pandas & $\geq$2.0 & CSV parsing for batch mode \\
numpy & $\geq$1.24 & Array ops for preprocessing \\
pytest & $\geq$7.0 & Unit tests \\
Playwright & $\geq$1.40 & E2E approve-flow test (optional) \\
\bottomrule
\end{tabularx}
\end{table}

Deployment: Streamlit Cloud uses \texttt{packages.txt} and \texttt{sources.list} to install Tesseract 5.3 on Debian (bookworm).

\section{Assumptions}

Input: Label images are flat (front/back photos or scans), not 3D bottle shots. Application data is entered manually (form or CSV); there is no COLA integration. Beverage type (spirits / wine / beer) is known and drives which rules apply.

OCR and extraction: Tesseract handles typical label layouts. Text is assumed left-to-right, top-to-bottom; multi-column layouts are split on large horizontal gaps. Government warning is usually in a distinct column; Serving Facts is filtered out. Brand extraction uses domain suffixes (Distillery, Brewery, Winery) and strips corp suffixes (Inc, LLC, Co). Class/type uses a keyword list from config (27 CFR Parts 4, 5, 7). Net contents supports metric (mL, L) and imperial (fl oz, qt, pt, gal); compound values like ``1 PINT 8 FL OZ'' are converted. Bottler is found via header patterns (Distilled and Bottled by, Produced by, etc.) or fallback.

Rules: Brand and class/type use rapidfuzz with configurable thresholds (pass $\geq$90\%, needs review $\geq$70\%). Government warning must contain required wording; minor OCR variations are allowed. Net contents are validated against a standard-of-fill list in config (27 CFR 5.203). Origin: bottler required; country of origin required when \texttt{imported=true}. Conditional statements (sulfites, FD\&C Yellow No.\ 5, carmine, wood treatment, age, neutral spirits) are required when application flags say so.

Data: Batch results are in-session only. Approve flow is persisted in \texttt{data/applications.json}.

\section{Limitations}

OCR: No font-size detection, so emphasized warning cannot be checked for size. Standard of fill uses a fixed list in config, not full CFR logic. Handwritten or low-quality images may fail. Non-standard layouts can confuse extraction. Class/type relies on a keyword list; novel variants may not match.

Rules: Emphasized warning is checked for caps and distinct block only; no font-size enforcement. Conditional statements are regex-based; complex phrasing may not match. Age statement uses a config-driven whisky threshold (4 years), not full CFR 5.40(a).

System: No COLA integration. Batch runs sequentially. Sample images are provided; no built-in benchmark dataset.

\section{Extensibility}

OCR can be swapped (e.g.\ for a cloud API). Rules live in \texttt{rules/engine.py} and \texttt{config/rules.yaml}. \texttt{pipeline.run\_pipeline()} can be exposed for COLA or external integration.

\section{File Structure}

\begin{lstlisting}
app.py                 # Entry point (streamlit run app.py)
scripts/
  run.py               # Cross-platform launcher
  setup.py             # Cross-platform setup
  compare_test_images.py
src/
  app.py               # Streamlit UI
  ocr.py               # Tesseract + preprocessing
  extraction.py        # Field extraction from OCR blocks
  pipeline.py          # Orchestration: OCR -> extraction -> rules -> scoring
  scoring.py           # Overall status from rule results
  storage.py           # Local JSON for approve flow
  ui_utils.py          # UI helpers
  rules/
    engine.py          # Rule evaluation (identity, alcohol, warning, origin, other)
config/
  rules.yaml           # Thresholds, patterns, beverage types, conditionals
sample_data/
  batch_example.csv    # Example batch CSV
  test_1.jpg...       # Sample label images
  test_images.zip      # Same images for batch ZIP upload
\end{lstlisting}

\section{References}

\begin{itemize}
    \item 27 CFR Part 4 (Wine labels)
    \item 27 CFR Part 5 (Distilled spirits labels)
    \item 27 CFR Part 7 (Malt Beverage labels)
    \item TTB Beverage Alcohol Manual (BAM)
\end{itemize}

\end{document}
